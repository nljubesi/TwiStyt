{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(48, 48, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 355,649\n",
      "Trainable params: 355,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for langs in ('NL','FR','IT','PT','ES'):\n",
    "    for gend in ('M','F'):\n",
    "        os.system('cp '+langs+'/imgs/'+gend+'/* ALL-DE/imgs/'+gend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9648 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                  )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'ALL-DE/imgs',\n",
    "        target_size=(48,48),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        'DE/imgs',\n",
    "        target_size=(48,48),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "301/301 [==============================] - 17s - loss: 0.6949 - acc: 0.5242 - val_loss: 0.6994 - val_acc: 0.5050\n",
      "Epoch 2/30\n",
      "301/301 [==============================] - 16s - loss: 0.6895 - acc: 0.5422 - val_loss: 0.6987 - val_acc: 0.5050\n",
      "Epoch 3/30\n",
      "301/301 [==============================] - 16s - loss: 0.6898 - acc: 0.5404 - val_loss: 0.7037 - val_acc: 0.4900\n",
      "Epoch 4/30\n",
      "301/301 [==============================] - 16s - loss: 0.6885 - acc: 0.5411 - val_loss: 0.7042 - val_acc: 0.5050\n",
      "Epoch 5/30\n",
      "301/301 [==============================] - 16s - loss: 0.6887 - acc: 0.5440 - val_loss: 0.7025 - val_acc: 0.4950\n",
      "Epoch 6/30\n",
      "301/301 [==============================] - 16s - loss: 0.6889 - acc: 0.5411 - val_loss: 0.6964 - val_acc: 0.5200\n",
      "Epoch 7/30\n",
      "301/301 [==============================] - 16s - loss: 0.6857 - acc: 0.5484 - val_loss: 0.7046 - val_acc: 0.4850\n",
      "Epoch 8/30\n",
      "301/301 [==============================] - 16s - loss: 0.6863 - acc: 0.5541 - val_loss: 0.6965 - val_acc: 0.4950\n",
      "Epoch 9/30\n",
      "301/301 [==============================] - 16s - loss: 0.6855 - acc: 0.5484 - val_loss: 0.6934 - val_acc: 0.5050\n",
      "Epoch 10/30\n",
      "301/301 [==============================] - 16s - loss: 0.6849 - acc: 0.5527 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 11/30\n",
      "301/301 [==============================] - 16s - loss: 0.6820 - acc: 0.5600 - val_loss: 0.6956 - val_acc: 0.5050\n",
      "Epoch 12/30\n",
      "301/301 [==============================] - 16s - loss: 0.6832 - acc: 0.5546 - val_loss: 0.6995 - val_acc: 0.5050\n",
      "Epoch 13/30\n",
      "301/301 [==============================] - 16s - loss: 0.6810 - acc: 0.5591 - val_loss: 0.6836 - val_acc: 0.5850\n",
      "Epoch 14/30\n",
      "301/301 [==============================] - 16s - loss: 0.6795 - acc: 0.5624 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 15/30\n",
      "301/301 [==============================] - 16s - loss: 0.6776 - acc: 0.5638 - val_loss: 0.6806 - val_acc: 0.5450\n",
      "Epoch 16/30\n",
      "301/301 [==============================] - 16s - loss: 0.6768 - acc: 0.5744 - val_loss: 0.6850 - val_acc: 0.5500\n",
      "Epoch 17/30\n",
      "301/301 [==============================] - 16s - loss: 0.6754 - acc: 0.5750 - val_loss: 0.6879 - val_acc: 0.5250\n",
      "Epoch 18/30\n",
      "301/301 [==============================] - 16s - loss: 0.6740 - acc: 0.5817 - val_loss: 0.6964 - val_acc: 0.5100\n",
      "Epoch 19/30\n",
      "301/301 [==============================] - 16s - loss: 0.6741 - acc: 0.5796 - val_loss: 0.6865 - val_acc: 0.5400\n",
      "Epoch 20/30\n",
      "301/301 [==============================] - 16s - loss: 0.6739 - acc: 0.5773 - val_loss: 0.7005 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "301/301 [==============================] - 16s - loss: 0.6713 - acc: 0.5834 - val_loss: 0.7014 - val_acc: 0.5400\n",
      "Epoch 22/30\n",
      "301/301 [==============================] - 16s - loss: 0.6729 - acc: 0.5772 - val_loss: 0.6703 - val_acc: 0.5450\n",
      "Epoch 23/30\n",
      "301/301 [==============================] - 16s - loss: 0.6691 - acc: 0.5848 - val_loss: 0.6795 - val_acc: 0.5500\n",
      "Epoch 24/30\n",
      "301/301 [==============================] - 16s - loss: 0.6699 - acc: 0.5848 - val_loss: 0.6800 - val_acc: 0.5700\n",
      "Epoch 25/30\n",
      "301/301 [==============================] - 16s - loss: 0.6671 - acc: 0.5923 - val_loss: 0.6783 - val_acc: 0.5600\n",
      "Epoch 26/30\n",
      "301/301 [==============================] - 16s - loss: 0.6700 - acc: 0.5781 - val_loss: 0.6810 - val_acc: 0.5300\n",
      "Epoch 27/30\n",
      "301/301 [==============================] - 16s - loss: 0.6681 - acc: 0.5884 - val_loss: 0.6660 - val_acc: 0.5950\n",
      "Epoch 28/30\n",
      "301/301 [==============================] - 16s - loss: 0.6669 - acc: 0.5853 - val_loss: 0.6842 - val_acc: 0.5300\n",
      "Epoch 29/30\n",
      "301/301 [==============================] - 16s - loss: 0.6666 - acc: 0.5842 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 30/30\n",
      "301/301 [==============================] - 16s - loss: 0.6642 - acc: 0.5958 - val_loss: 0.6754 - val_acc: 0.5700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=301,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58810368/58889256 [============================>.] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(48, 48, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9648 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(48, 48),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features('ALL-DE/imgs/', 9648)\n",
    "validation_features, validation_labels = extract_features('DE/imgs/', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (9648, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (200, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9648 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "9648/9648 [==============================] - 4s - loss: 0.7178 - acc: 0.5747 - val_loss: 0.6271 - val_acc: 0.6550\n",
      "Epoch 2/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6407 - acc: 0.6288 - val_loss: 0.6048 - val_acc: 0.6600\n",
      "Epoch 3/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6253 - acc: 0.6503 - val_loss: 0.5881 - val_acc: 0.6700\n",
      "Epoch 4/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6160 - acc: 0.6533 - val_loss: 0.5945 - val_acc: 0.6400\n",
      "Epoch 5/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6100 - acc: 0.6647 - val_loss: 0.5968 - val_acc: 0.6550\n",
      "Epoch 6/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6063 - acc: 0.6696 - val_loss: 0.5900 - val_acc: 0.6650\n",
      "Epoch 7/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.6011 - acc: 0.6693 - val_loss: 0.5790 - val_acc: 0.6800\n",
      "Epoch 8/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5990 - acc: 0.6763 - val_loss: 0.5867 - val_acc: 0.6650\n",
      "Epoch 9/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5954 - acc: 0.6778 - val_loss: 0.5857 - val_acc: 0.6750\n",
      "Epoch 10/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5951 - acc: 0.6805 - val_loss: 0.5832 - val_acc: 0.6850\n",
      "Epoch 11/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5946 - acc: 0.6825 - val_loss: 0.5791 - val_acc: 0.6950\n",
      "Epoch 12/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5899 - acc: 0.6799 - val_loss: 0.5778 - val_acc: 0.6850\n",
      "Epoch 13/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5858 - acc: 0.6888 - val_loss: 0.5829 - val_acc: 0.6950\n",
      "Epoch 14/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5890 - acc: 0.6886 - val_loss: 0.5789 - val_acc: 0.6950\n",
      "Epoch 15/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5874 - acc: 0.6877 - val_loss: 0.5783 - val_acc: 0.6900\n",
      "Epoch 16/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5858 - acc: 0.6864 - val_loss: 0.5874 - val_acc: 0.6850\n",
      "Epoch 17/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5831 - acc: 0.6853 - val_loss: 0.5856 - val_acc: 0.6950\n",
      "Epoch 18/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5859 - acc: 0.6908 - val_loss: 0.5753 - val_acc: 0.7000\n",
      "Epoch 19/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5859 - acc: 0.6909 - val_loss: 0.5801 - val_acc: 0.7100\n",
      "Epoch 20/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5823 - acc: 0.6962 - val_loss: 0.5781 - val_acc: 0.7000\n",
      "Epoch 21/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5811 - acc: 0.6926 - val_loss: 0.5774 - val_acc: 0.6950\n",
      "Epoch 22/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5806 - acc: 0.6957 - val_loss: 0.5830 - val_acc: 0.7000\n",
      "Epoch 23/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5790 - acc: 0.6991 - val_loss: 0.5802 - val_acc: 0.7000\n",
      "Epoch 24/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5820 - acc: 0.6958 - val_loss: 0.5757 - val_acc: 0.7000\n",
      "Epoch 25/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5808 - acc: 0.6953 - val_loss: 0.5843 - val_acc: 0.7050\n",
      "Epoch 26/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5782 - acc: 0.7025 - val_loss: 0.5846 - val_acc: 0.6700\n",
      "Epoch 27/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5789 - acc: 0.7041 - val_loss: 0.5746 - val_acc: 0.6900\n",
      "Epoch 28/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5774 - acc: 0.7009 - val_loss: 0.5817 - val_acc: 0.6850\n",
      "Epoch 29/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5758 - acc: 0.7005 - val_loss: 0.5881 - val_acc: 0.7000\n",
      "Epoch 30/30\n",
      "9648/9648 [==============================] - 3s - loss: 0.5781 - acc: 0.6975 - val_loss: 0.5841 - val_acc: 0.6900\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "topmodel = models.Sequential()\n",
    "topmodel.add(layers.Dense(128, activation='relu', input_dim=4 * 4 * 512))\n",
    "topmodel.add(layers.Dropout(0.5))\n",
    "topmodel.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "topmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "tophistory = topmodel.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
